# NCS 데이터 탐색

# 모집단 - 분석을 하기 위해 관심이 있는 대상 전체
#          추출 단위가 유한/무한인 유한/무한 모집단

# 표본추출 - 모집단의 부분 집합을 추출하는 것
#            모집단 전체에 대한 분석이 사실상 불가능 하다는 제약
#            전수조사를 하면 오히려 막대한 비용/시간 소요

# 통계 분석 - 표본이 가지고 있는 모집단 성질의 일부만을
#             가지고 모집단의 특성을 합리적으로 추론하는 것

# 모수 - 모집단의 통계적 속성을 나타내는 수치
#        데이터의 위치 정보를 나타내는 평균(mean), 중앙값(median)
#        분포에 대한 지표인 분산(variance) 및 표준편차(standard deviation) 등

# 통계 분석의 과정은 총 6단계로 구성

# 표본 추출 기법
# 단순 무작위 추출 - 모집단에서 정해진 규칙 없이 표본을 추출하는 방식
# 100개의 전구에서 무작위로 10개의 전구를 추출

# 계통 추출 - 모집단을 일정한 간격으로 추출하는 방식
# 100명의 사람에게 번호표를 나눠주고
# 끝자리가 7로 끝나는 사람들을 선정

# 층화 추출 - 모집단을 여러 계층으로 나누고,
# 계층별로 무작위 추출을 수행하는 방식
# 조사 지역을 도 별로 나누고,
# 각 도에서 무작위로 100명씩 선정

# 군집 추출 - 모집단을 여러 군집으로 나누고,
# 일부 군집의 전체를 추출하는 방식
# 100개의 전구에 무작위로 검은색, 노란색, 파란색을
# 칠하고 파란색의 전구를 모두 추출

# 측정
# 관심있는 대상을 분석 목적에 맞게 데이터화 하는 것
# 명목 척도 - 이메일 주소, 인터넷 계정, 옷 색깔, 성별
# 순서 척도 - 직급, 영화 평점, 선호도
# 구간 척도 - 온도, 지능지수
# 비율 척도 - 질량, 나이, 개수, 길이

# 잡음
# 대상을 잘못 측정하게 해서 참값에서 벗어나게 만드는
# 임의의 존재

# 기초 통계기법
# 평균(mean) -데이터 집합이 어떤 값을 중심으로 분포되어 있는지를
#             알기 위해 많이 사용되는 평균
# 중앙값(median) - 데이터 집합을 크기에 따라 차례로 나열했을 때
#                  가운데에 놓이는 값
# 최빈치(mode) - 가장 많은 빈도를 갖는 데이터를 의미
# 분산(Variance) - 분산은 평균으로부터 각각의 데이터가 얼마나 떨어져
#                  있는지를 종합적으로 나타내는 지표
# 표준편차(Standard Deviation) - 데이터 집합의 확산 정도를 나타내는
#         분산의 단위를 본래의 척도와 맞춰주기 위해 분산을 제곱근 한
#         것을 표준편차라고 한다
# 범위(Range) - 데이터 집합에서 최대값(max)과 최소값(min)을 이용하여 확산 
#               정도를 간단하게 나타낸 것
# 히스토그램 - 단일 속성에 대한 데이터 분포를 시각적으로 알기 위해 주로
#              사용되는 그래프
# 박스수염 그래프 - 데이터 집합의 최대값, 최소값, 중앙값, 사분편차(데이터를
#                   크기순으로 나열하여 작은 쪽에서부터 각각 Q1, Q3 라고
#                   할 때, 데이터들이 어떤 모양으로 분포되어 있으며,
#                   극단 값들이 어떤지를 쉽게 알 수 있도록 하는 그림이다
# 05. 분석용 PDF

# p22 예제) 자료 측정을 통해 디스플레이 크기, 출시연도, 구매 시기 등의 
# 세 가지 속성에 대한 표를 만들고 기재하여 데이터 집합을 얻는다.
# R을 이용하여 수집된 데이터를 분석할 때 테이블의 형태로 데이터를 읽어
# 들이기 위해 .csv 파일의 형태로 저장한다.

phone <- read.csv('c:/Java/phone-01.csv', header=F)

summary(phone) # 기술통계 요약

var(phone) # 분산

sqrt(var(phone)) # 표준편차 (분산의 제곱근)

hist(phone$V1) # 출시년도 빈도
hist(phone$V2) # 구매시기 빈도
hist(phone$V3) # 화면크기 빈도


# 상관분석
# 두 변수 간의 선형적인 관계를 정량적인 지표
# 두 변수 간의 상관 정도를 나타내는 공분산을 이용
# 공분산은 한 변수가 상승할 때 나머지 변수가 상승하는
# 경향이 존재하면 양의 값을 갖고,
# 하강하는 경향이 존재하면 음의 값을 갖는다
# 예) 연령에 따른 스마트폰 데이터 사용량간의
# 관계를 알고자 할때


# 상관계수
# 두 모집단을 나타내는 변수 x1, x2 간의
# 선형관계를 나타내는 척도
# 각 변수의 표준편차의 곱으로 나누어 주어
# 선형관계의 정도를 표현
# 실제 데이터는 모집단 일부분이기 때문에 표본 상관계수를
# 사용 - 피어슨 상관계수(Pearson correlation)


# 회귀분석
# 한 변수가 다은 변수에 미치는 영향을 함수 형태로
# 추정하기 위해 고안된 기법
# 한 변수가 다른 변수에 1차원 혹은 2차원 이상의
# 영향을 주고 있다는 가정 아래 수행
# 영향을 주는 변수 - 독립변수(independent variable)
# 영향을 받는 변수 - 종속변수(dependent variable)
# 예) 스마트폰에 설치된 애플리케이션의 개수가 데이터
# 사용량에 미치는 영향을 분석


# 회귀분석 종류
# 단순 회귀분석 - 독립변수가 1개이면 종속변수와의 관계가
# 선형적(1차 함수) 독립변수 x1이 종속변수 y에 선형적인
# 영향을 미친다는 가정

# 다중회귀분석 - 독립변수가 2개 이상이며 종속변수와의
# 관계가 선형적 (1차 함수) n 개의 변수가 y 에 선형적인
# 영향을 미틴다는 가정

# 곡선회귀분석 - 독립변수가 1개이며 종속변수와의 관계사
# 곡선적(2차 함수 이상) 독립변수 x1 이 y에 k차원 함수형태
# 의 영향을 미친다는 가정

# 회귀분석시 변수들의 유의차 검증
# 데이터를 이용한 회귀 분석을 수행할 때,
# 독립변수 x1,x2,...,xn 들에 대한 분산 분석 결과에서
# p-value > 0.05 인 변수들은 종속변수 y 에 대한 유의한
# 것으로 판정


# 수집된 데이터의 변수들과 데이터 사용량에 대한 유의성파악
phone02 <- read.table('c:/Java/phone-02.csv', header=F, sep=',')

# 공분산으로 상관계수를 측정
cor(phone02)

# 데이터 사용량V9은 평균스마트폰 사용시간V7과
# 상관관계 유의미

# 가장 높은유의성을 갖는  변수가 데이터 사용량에
# 미치는 영향을 추정하는 단순회귀분석 실시
p <- lm( phone02$V9~phone02$V7, data=phone02 )

# 회귀식 : y = -272.001 + 6.283x

summary( p )

# 변수간 관계확인
# 분석모형 구축시 유의사항
# 변수의 유의성 검증 후 유의성 높은 최소한의
# 변수들로 분석 모형을 검증

# 분석 모형을 구축하는 데에는 [일반화 오류]와
# [훈련 오류]라느 두 가지 종류의 오류가 발생

# 일반화 오류 - 분석 모형을 만들 때 주어진
#               데이터 집합의 특성을 지나치게 반영 (과적합)

# 훈련 오류 - 주어진 데이터 집합에 부차적인 특성과 잡음이
#             있다는 점을 고려하여 특성을 덜 반영 (미적합)

# 분석모형 검증
# 모집단에서 표본 추출한 데이터 집합을 이용하여
# 모집단을 합리적으로 추론하는 타당한 분석 모형을 구축
# - 일반화/훈련 오류 모두 고려

# 분석 모형에서 산출된 값과 실제 값과의 차이의
# 제곱 평균을 예측 오차로 계산(RMSE)하여 수행

# 분석 모형의 타당성 평가
# 분석 모형이 실제로 현실을 잘 묘사하고 있는지 확인

# 주어진 데이터를 모형에 입력하여 얻은 결과와
# 실제 데이터값 간의 차이가 적으면 좋은 모형

# 분석 모형 보정
# 시뮬레이션  -분석 모형이 유효한지 판단하기 위해
# 시뮬레이션을 통해 모형의 타당성과 적합성을 평가
# 시뮬레이션 결과가 실제 데이터값과 차이가 크면
# 시뮬레이션 재검토/수정 필요

# 무작의 추출을 통해 7:3 비율로 training/test 데이터 준비
s <- read.table('c:/Java/phone-02.csv',
                header=F, sep=',')
for(i in 1:5) {
  tr <- sample(nrow(s), replace=F, size=nrow(s)*0.7)
  tr
  
  # 학습/훈련 데이터 추출
  s_train <- s[tr, ]
  s_test<- s[-tr, ]
  
  # 회귀모형 구축 - 학습 데이터 집합사용, 회귀식 작성
  lm(s_train[,9]~s_train[,7], data=s_train)
  # (Intercept)  s_train[, 7]  
  # -223.760         5.678
  
  # y = -223.760 + (5.678 * x)
  
  # 회귀식을 함수로 만들고 시험 데이터로 확인
  lrm <- function(x) {
    -223.760 + (5.678 * x)
  }
  
  test_result <- lrm(s_test[,7]) # 추정치
  
  # RMSE 계산
  rmse <- sum(abs(s_test[,7] - lrm(s_test[,7]))) / sqrt(nrow(s_test))
  
  print(rmse)
  
} # for 문 닫기


# 데이터 정제하기
# 데이터 유형 추출 - which
l2016 <- which(s[,1] == 2016) # 2016 출시상품 index 표시
s[l2016, ]                    # 2016 출시상품 출력

# 특정범위 데이터 추출
gt_500 <- s[,9] > 500 # 일일데이터사용량 500MB이상
s[gt_500, ]

# 일일 데이터사용량이 400MB 이상인 샘플
gt_400 <- s[,9] >= 400 # 일일데이터사용량 400MB 이상인 샘플
s[gt_400, ]

# 일일 데이터사용량이 400MB 이하인 샘플
lt_400 <- s[,9] <= 400 # 일일데이터사용량 400MB 이하인 샘플
s[lt_400, ]

# KNN 알고리즘 군집화
# 차종, 마력, 경기용차여부, 빠른지여부
# 혼다어코드, 180, F, F
# 유고, 500, T, T
# 드롤리안, 200, T, F
# 쉬보레카미로, 400, T, ?

# 유클리드 거리측정 이용 sqrt((p1-p3)**2 + (p2-p4)**2)
# 차종, 마력, 빠른지여부
# 혼다어코드, 180(p1), 0(p2) : 
# 유고, 500(p3), 1(p4)
# 드롤리안, 200, 0
# 쉬보레카미로, 400, ?


km3 <- kmeans(s[,9], 3)
km3$cluster # 군집 벡터값 출력
km3$centers # 군집 벡터값 평균
s_km3 <- cbind(s, km3$cluster)
s_km3

km5 <- kmeans(s[,9], 5)
km5$cluster # 군집 벡터값 출력
km5$centers  # 군집 벡터값 평균
km5_cluster <- km5$cluster

for(i in 1:5) {
  km5_cluster[km5_cluster == i] <- km5$centers[i]
}

s_km5 <- cbind(s, km5_cluster) # 평균값 대체
s_km5

# 데이터 정제
# 데이터를 불완전하게 만드는 요소
# 보통 결측치(missing value)와 잡음 존재

# 결측치 - 샘플에서 누락된 변수값을 지칭
# 오류로 인해 발생할 수도 있지만, 단순히
# 조사 대상이 측정을 원하지 않을 때에도 발생
# 해결방법 : 샘플제거, 해당 변수 제거,
# 결측치 무시, 결측치 추정(평균, 중앙값, 회귀분석)

# 이상치 - 데이터집합에서 대부분의 다른 샘플과 현저한
# 차이를 나타내는 셈플, 변수값
# 오류면 제거, 이상치면 관심을 가지며 분석 시행

